{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Group Responsible - Initial Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>iyear</th>\n",
       "      <th>country</th>\n",
       "      <th>crit1</th>\n",
       "      <th>crit2</th>\n",
       "      <th>crit3</th>\n",
       "      <th>attacktype1</th>\n",
       "      <th>targtype1</th>\n",
       "      <th>targsubtype1</th>\n",
       "      <th>weaptype1</th>\n",
       "      <th>weapsubtype1</th>\n",
       "      <th>ransom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1970</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1970</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978</td>\n",
       "      <td>1970</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679</td>\n",
       "      <td>1970</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679</td>\n",
       "      <td>1970</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   groupId  iyear  country  crit1  crit2  crit3  attacktype1  targtype1  \\\n",
       "0        6   1970      130      1      1      1            6          7   \n",
       "1      204   1970      217      1      1      1            2          3   \n",
       "2      978   1970      218      1      1      1            1          3   \n",
       "3      679   1970      217      1      1      1            7          4   \n",
       "4      679   1970      217      1      1      1            7          2   \n",
       "\n",
       "   targsubtype1  weaptype1  weapsubtype1  ransom  \n",
       "0          45.0         13           0.0     1.0  \n",
       "1          22.0          5           5.0     0.0  \n",
       "2          25.0          5           2.0     0.0  \n",
       "3          28.0          8          19.0     0.0  \n",
       "4          21.0          8          20.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(88657, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# if csv isn't there:\n",
    "# %run ./CreateCSVFile.py\n",
    "gtd = pd.read_csv('gtd_processed_11features.csv', encoding='latin1', low_memory=False)\n",
    "#gtd = gtd.tail(10000) #TODO: only in to speed up for now\n",
    "display(gtd.head(5))\n",
    "gtd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split-out validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = gtd.values\n",
    "seed = 188\n",
    "X = array[:,1:]\n",
    "Y = array[:,0]\n",
    "# print X\n",
    "validation_size = 0.20 #TODO: lower for final\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.302968% (0.005750) - 6.834 seconds\n",
      "KNN: 0.657032% (0.005536) - 8.244 seconds\n",
      "CART: 0.706761% (0.004214) - 12.792 seconds\n",
      "GNB: 0.064843% (0.003521) - 17.24 seconds\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "#models.append(('LR', LogisticRegression())) #LR: 0.374750% (0.012207) - 164.417 seconds\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC())) #Too slow for this many samples - O(N^3)\n",
    "  \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    " \n",
    "#%timeit\n",
    "for name, model in models:\n",
    "    start_time = time.time()\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed) #ensure same seed so models are directly comparable\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f%% (%f) - %s seconds\" % (name, cv_results.mean(), cv_results.std(), round((time.time() - start_time),3))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Features, .Tail(10000)\n",
    "LR: 0.374750% (0.012207) - 164.417 seconds\n",
    "\n",
    "LDA: 0.426000% (0.014946) - 0.313 seconds\n",
    "\n",
    "KNN: 0.726875% (0.012071) - 0.312 seconds\n",
    "\n",
    "CART: 0.762125% (0.011389) - 0.371 seconds\n",
    "\n",
    "GNB: 0.102750% (0.009401) - 0.763 seconds\n",
    "\n",
    "SVM: 0.723875% (0.014879) - 342.715 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Features, All Rows\n",
    "LDA: 0.302968% (0.005750) - 6.834 seconds\n",
    "KNN: 0.657032% (0.005536) - 8.244 seconds\n",
    "CART: 0.706761% (0.004214) - 12.792 seconds\n",
    "GNB: 0.064843% (0.003521) - 17.24 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b54f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "# ?plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605\n",
      "[[1 0 0 ..., 0 0 0]\n",
      " [0 7 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       12.0       0.50      0.33      0.40         3\n",
      "       18.0       0.35      0.35      0.35        20\n",
      "       20.0       0.00      0.00      0.00         1\n",
      "       22.0       0.00      0.00      0.00         1\n",
      "       25.0       0.43      0.27      0.33        11\n",
      "       35.0       0.67      0.50      0.57         4\n",
      "       37.0       0.00      0.00      0.00         1\n",
      "       39.0       0.00      0.00      0.00         2\n",
      "       48.0       0.00      0.00      0.00         1\n",
      "       53.0       0.33      0.63      0.44        19\n",
      "       58.0       0.50      0.58      0.54        24\n",
      "       59.0       0.00      0.00      0.00         2\n",
      "       60.0       0.40      0.40      0.40         5\n",
      "       62.0       1.00      1.00      1.00       134\n",
      "       64.0       0.00      0.00      0.00         1\n",
      "       66.0       0.00      0.00      0.00         0\n",
      "       71.0       1.00      1.00      1.00         3\n",
      "       81.0       0.60      0.92      0.73        13\n",
      "       86.0       0.83      0.83      0.83         6\n",
      "       90.0       0.83      0.71      0.77         7\n",
      "       92.0       0.00      0.00      0.00         0\n",
      "       98.0       0.00      0.00      0.00         0\n",
      "      100.0       0.50      1.00      0.67         4\n",
      "      108.0       0.00      0.00      0.00         1\n",
      "      112.0       0.50      1.00      0.67         1\n",
      "      163.0       0.89      0.89      0.89         9\n",
      "      168.0       1.00      1.00      1.00         1\n",
      "      174.0       0.25      0.33      0.29         6\n",
      "      175.0       0.25      0.20      0.22        10\n",
      "      177.0       0.00      0.00      0.00         0\n",
      "      178.0       0.33      0.50      0.40         2\n",
      "      183.0       0.00      0.00      0.00         1\n",
      "      185.0       0.50      0.59      0.54        17\n",
      "      186.0       0.67      1.00      0.80         2\n",
      "      187.0       0.46      0.46      0.46        13\n",
      "      188.0       0.33      1.00      0.50         1\n",
      "      197.0       0.00      0.00      0.00         0\n",
      "      214.0       0.93      0.82      0.87        79\n",
      "      230.0       0.50      1.00      0.67         2\n",
      "      248.0       0.50      1.00      0.67         1\n",
      "      257.0       0.23      0.33      0.27        21\n",
      "      261.0       1.00      0.80      0.89         5\n",
      "      267.0       0.00      0.00      0.00         1\n",
      "      268.0       0.00      0.00      0.00         0\n",
      "      271.0       0.00      0.00      0.00         0\n",
      "      273.0       0.00      0.00      0.00         0\n",
      "      295.0       0.00      0.00      0.00         6\n",
      "      303.0       0.00      0.00      0.00         0\n",
      "      308.0       0.00      0.00      0.00         1\n",
      "      309.0       0.75      0.75      0.75         4\n",
      "      340.0       0.00      0.00      0.00         1\n",
      "      354.0       0.00      0.00      0.00         9\n",
      "      361.0       0.70      0.82      0.75        39\n",
      "      365.0       0.20      0.12      0.15         8\n",
      "      372.0       0.00      0.00      0.00         1\n",
      "      382.0       0.00      0.00      0.00         4\n",
      "      384.0       0.00      0.00      0.00         2\n",
      "      385.0       0.50      0.33      0.40         6\n",
      "      386.0       0.50      0.50      0.50         2\n",
      "      389.0       0.00      0.00      0.00         4\n",
      "      392.0       0.00      0.00      0.00         2\n",
      "      393.0       1.00      0.33      0.50         3\n",
      "      395.0       1.00      1.00      1.00         1\n",
      "      398.0       0.00      0.00      0.00         4\n",
      "      402.0       0.90      0.90      0.90       102\n",
      "      406.0       0.00      0.00      0.00         1\n",
      "      408.0       0.00      0.00      0.00         3\n",
      "      414.0       0.00      0.00      0.00         0\n",
      "      439.0       0.50      1.00      0.67         7\n",
      "      440.0       0.00      0.00      0.00         0\n",
      "      442.0       0.91      0.93      0.92       336\n",
      "      445.0       0.00      0.00      0.00         0\n",
      "      446.0       1.00      0.33      0.50         3\n",
      "      450.0       0.00      0.00      0.00         1\n",
      "      451.0       0.00      0.00      0.00         2\n",
      "      452.0       1.00      1.00      1.00         2\n",
      "      453.0       0.00      0.00      0.00         1\n",
      "      454.0       0.00      0.00      0.00         2\n",
      "      455.0       0.33      1.00      0.50         1\n",
      "      457.0       0.00      0.00      0.00         1\n",
      "      465.0       0.00      0.00      0.00         0\n",
      "      469.0       0.73      0.80      0.76        10\n",
      "      471.0       0.00      0.00      0.00         4\n",
      "      478.0       0.67      0.29      0.40         7\n",
      "      479.0       0.00      0.00      0.00         1\n",
      "      485.0       0.00      0.00      0.00         1\n",
      "      487.0       0.75      0.60      0.67         5\n",
      "      506.0       0.31      0.27      0.29        33\n",
      "      514.0       0.00      0.00      0.00         0\n",
      "      520.0       0.00      0.00      0.00         1\n",
      "      526.0       0.00      0.00      0.00         2\n",
      "      527.0       0.50      0.25      0.33         4\n",
      "      528.0       0.92      0.89      0.91       120\n",
      "      534.0       0.11      0.33      0.17         3\n",
      "      535.0       0.00      0.00      0.00         3\n",
      "      546.0       0.00      0.00      0.00         0\n",
      "      555.0       0.83      0.83      0.83         6\n",
      "      558.0       0.00      0.00      0.00         1\n",
      "      559.0       0.00      0.00      0.00         1\n",
      "      564.0       0.00      0.00      0.00         0\n",
      "      573.0       0.00      0.00      0.00         0\n",
      "      575.0       0.00      0.00      0.00         3\n",
      "      580.0       0.74      0.74      0.74        92\n",
      "      581.0       1.00      1.00      1.00         1\n",
      "      584.0       0.00      0.00      0.00         2\n",
      "      589.0       0.00      0.00      0.00         1\n",
      "      600.0       0.00      0.00      0.00         0\n",
      "      612.0       0.00      0.00      0.00         0\n",
      "      615.0       0.00      0.00      0.00         0\n",
      "      622.0       1.00      1.00      1.00        16\n",
      "      630.0       0.00      0.00      0.00         0\n",
      "      633.0       1.00      1.00      1.00         1\n",
      "      634.0       0.00      0.00      0.00         0\n",
      "      641.0       0.38      0.20      0.26        25\n",
      "      646.0       0.00      0.00      0.00         1\n",
      "      651.0       0.00      0.00      0.00         0\n",
      "      652.0       0.00      0.00      0.00         0\n",
      "      657.0       0.94      0.89      0.91        18\n",
      "      665.0       0.00      0.00      0.00         3\n",
      "      666.0       0.00      0.00      0.00         3\n",
      "      672.0       0.00      0.00      0.00         1\n",
      "      677.0       0.73      0.74      0.74        66\n",
      "      682.0       0.64      0.88      0.74         8\n",
      "      683.0       0.00      0.00      0.00         3\n",
      "      688.0       0.00      0.00      0.00         2\n",
      "      689.0       0.00      0.00      0.00         3\n",
      "      694.0       1.00      1.00      1.00         1\n",
      "      703.0       1.00      1.00      1.00         3\n",
      "      707.0       0.88      0.91      0.89        56\n",
      "      708.0       0.00      0.00      0.00         1\n",
      "      712.0       1.00      1.00      1.00         5\n",
      "      717.0       0.00      0.00      0.00         3\n",
      "      721.0       0.33      0.20      0.25         5\n",
      "      729.0       0.00      0.00      0.00         1\n",
      "      731.0       0.00      0.00      0.00         2\n",
      "      734.0       0.00      0.00      0.00         3\n",
      "      741.0       0.33      1.00      0.50         1\n",
      "      764.0       0.00      0.00      0.00         0\n",
      "      790.0       0.00      0.00      0.00         1\n",
      "      793.0       0.00      0.00      0.00         1\n",
      "      816.0       0.00      0.00      0.00         1\n",
      "      845.0       0.50      0.33      0.40         3\n",
      "      851.0       0.67      1.00      0.80         2\n",
      "      852.0       0.89      0.62      0.73        13\n",
      "      859.0       0.00      0.00      0.00         1\n",
      "      868.0       0.00      0.00      0.00         1\n",
      "      870.0       0.47      0.47      0.47        15\n",
      "      876.0       0.00      0.00      0.00         1\n",
      "      877.0       0.00      0.00      0.00         1\n",
      "      884.0       1.00      1.00      1.00         1\n",
      "      885.0       0.00      0.00      0.00         2\n",
      "      886.0       0.00      0.00      0.00         1\n",
      "      890.0       0.92      0.92      0.92        39\n",
      "      891.0       0.00      0.00      0.00         1\n",
      "      903.0       0.00      0.00      0.00         2\n",
      "      915.0       0.00      0.00      0.00         2\n",
      "      919.0       0.00      0.00      0.00         0\n",
      "      921.0       0.00      0.00      0.00         0\n",
      "      922.0       1.00      1.00      1.00         4\n",
      "      937.0       0.67      1.00      0.80         2\n",
      "      939.0       0.92      0.94      0.93       285\n",
      "      948.0       0.00      0.00      0.00         1\n",
      "      951.0       0.60      0.48      0.53        25\n",
      "      967.0       1.00      0.25      0.40         4\n",
      "      969.0       0.84      0.78      0.81        46\n",
      "      970.0       0.00      0.00      0.00         0\n",
      "      974.0       0.00      0.00      0.00         1\n",
      "      989.0       0.00      0.00      0.00         1\n",
      "      996.0       0.67      0.33      0.44         6\n",
      "      998.0       0.50      1.00      0.67         1\n",
      "     1003.0       0.50      0.20      0.29         5\n",
      "     1005.0       0.00      0.00      0.00         1\n",
      "     1019.0       1.00      1.00      1.00         2\n",
      "     1022.0       0.00      0.00      0.00         0\n",
      "     1028.0       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.76      0.76      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "cart = DecisionTreeClassifier()\n",
    "cart.fit(X_train, Y_train)\n",
    "predictions = cart.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
