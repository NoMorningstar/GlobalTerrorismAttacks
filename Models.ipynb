{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>iyear</th>\n",
       "      <th>country</th>\n",
       "      <th>attacktype1</th>\n",
       "      <th>weaptype1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78657</th>\n",
       "      <td>939</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78658</th>\n",
       "      <td>214</td>\n",
       "      <td>2015</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78659</th>\n",
       "      <td>384</td>\n",
       "      <td>2015</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78660</th>\n",
       "      <td>506</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78661</th>\n",
       "      <td>707</td>\n",
       "      <td>2015</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       groupId  iyear  country  attacktype1  weaptype1\n",
       "78657      939   2015        4            3          6\n",
       "78658      214   2015      147            2          5\n",
       "78659      384   2015      153            3          6\n",
       "78660      506   2015        4            6         13\n",
       "78661      707   2015      155            8         10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# if csv isn't there:\n",
    "# %run ./CreateCSVFile.py\n",
    "gtd = pd.read_csv('gtd_processed_5features.csv', encoding='latin1', low_memory=False)\n",
    "gtd = gtd.tail(10000) #TODO: only in to speed up for now\n",
    "display(gtd.head(5))\n",
    "gtd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split-out validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = gtd.values\n",
    "seed = 188\n",
    "X = array[:,1:]\n",
    "Y = array[:,0]\n",
    "# print X\n",
    "validation_size = 0.20 #TODO: lower for final\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.350250% (0.016675) - 57.74 seconds\n",
      "LDA: 0.425000% (0.011429) - 0.319 seconds\n",
      "KNN: 0.729375% (0.014930) - 0.279 seconds\n",
      "CART: 0.758375% (0.015115) - 0.141 seconds\n",
      "GNB: 0.155250% (0.015060) - 0.598 seconds\n",
      "SVM: 0.754875% (0.018578) - 69.904 seconds\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC())) #Too slow for this many samples - O(N^3)\n",
    "  \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    " \n",
    "#%timeit\n",
    "for name, model in models:\n",
    "    start_time = time.time()\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed) #ensure same seed so models are directly comparable\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f%% (%f) - %s seconds\" % (name, cv_results.mean(), cv_results.std(), round((time.time() - start_time),3))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEEOdzOzBP1/Nm7a4olphbcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11356ba10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "# ?plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n",
      "[[ 0  0  0 ...,  0  0  0]\n",
      " [ 0 11  0 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " ..., \n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         12       0.00      0.00      0.00         3\n",
      "         18       0.24      0.55      0.33        20\n",
      "         20       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         25       0.50      0.09      0.15        11\n",
      "         35       0.00      0.00      0.00         4\n",
      "         37       0.00      0.00      0.00         1\n",
      "         39       0.00      0.00      0.00         2\n",
      "         48       0.00      0.00      0.00         1\n",
      "         53       0.29      0.11      0.15        19\n",
      "         58       0.35      0.25      0.29        24\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       0.50      0.40      0.44         5\n",
      "         62       1.00      1.00      1.00       134\n",
      "         64       0.00      0.00      0.00         1\n",
      "         71       0.00      0.00      0.00         3\n",
      "         81       0.45      0.69      0.55        13\n",
      "         86       0.71      0.83      0.77         6\n",
      "         87       0.00      0.00      0.00         0\n",
      "         90       0.42      0.71      0.53         7\n",
      "        100       0.00      0.00      0.00         4\n",
      "        108       0.00      0.00      0.00         1\n",
      "        112       1.00      1.00      1.00         1\n",
      "        163       1.00      0.89      0.94         9\n",
      "        168       0.50      1.00      0.67         1\n",
      "        174       0.00      0.00      0.00         6\n",
      "        175       0.25      0.10      0.14        10\n",
      "        178       0.50      0.50      0.50         2\n",
      "        183       0.00      0.00      0.00         1\n",
      "        185       1.00      0.18      0.30        17\n",
      "        186       0.00      0.00      0.00         2\n",
      "        187       0.19      0.38      0.25        13\n",
      "        188       0.00      0.00      0.00         1\n",
      "        214       0.77      0.87      0.82        79\n",
      "        230       0.33      0.50      0.40         2\n",
      "        248       0.00      0.00      0.00         1\n",
      "        257       0.12      0.10      0.11        21\n",
      "        261       0.83      1.00      0.91         5\n",
      "        267       0.00      0.00      0.00         1\n",
      "        295       0.25      0.17      0.20         6\n",
      "        308       0.00      0.00      0.00         1\n",
      "        309       0.80      1.00      0.89         4\n",
      "        340       0.00      0.00      0.00         1\n",
      "        354       0.18      0.22      0.20         9\n",
      "        361       0.69      0.74      0.72        39\n",
      "        365       0.00      0.00      0.00         8\n",
      "        372       0.00      0.00      0.00         1\n",
      "        382       0.00      0.00      0.00         4\n",
      "        384       0.00      0.00      0.00         2\n",
      "        385       1.00      0.33      0.50         6\n",
      "        386       0.00      0.00      0.00         2\n",
      "        389       0.00      0.00      0.00         4\n",
      "        392       0.00      0.00      0.00         2\n",
      "        393       0.00      0.00      0.00         3\n",
      "        395       1.00      1.00      1.00         1\n",
      "        398       0.00      0.00      0.00         4\n",
      "        402       0.72      0.97      0.83       102\n",
      "        406       0.00      0.00      0.00         1\n",
      "        408       0.00      0.00      0.00         3\n",
      "        439       0.41      1.00      0.58         7\n",
      "        442       0.84      0.90      0.87       336\n",
      "        446       0.00      0.00      0.00         3\n",
      "        450       0.00      0.00      0.00         1\n",
      "        451       0.00      0.00      0.00         2\n",
      "        452       0.00      0.00      0.00         2\n",
      "        453       0.00      0.00      0.00         1\n",
      "        454       0.00      0.00      0.00         2\n",
      "        455       0.00      0.00      0.00         1\n",
      "        457       0.00      0.00      0.00         1\n",
      "        469       0.67      1.00      0.80        10\n",
      "        471       0.00      0.00      0.00         4\n",
      "        478       0.57      0.57      0.57         7\n",
      "        479       0.00      0.00      0.00         1\n",
      "        485       0.00      0.00      0.00         1\n",
      "        487       0.00      0.00      0.00         5\n",
      "        506       0.50      0.03      0.06        33\n",
      "        520       0.00      0.00      0.00         1\n",
      "        526       0.00      0.00      0.00         2\n",
      "        527       0.00      0.00      0.00         4\n",
      "        528       0.83      0.96      0.89       120\n",
      "        534       0.18      1.00      0.30         3\n",
      "        535       0.00      0.00      0.00         3\n",
      "        555       0.00      0.00      0.00         6\n",
      "        558       0.00      0.00      0.00         1\n",
      "        559       0.00      0.00      0.00         1\n",
      "        564       0.00      0.00      0.00         0\n",
      "        575       0.00      0.00      0.00         3\n",
      "        580       0.57      0.90      0.70        92\n",
      "        581       0.00      0.00      0.00         1\n",
      "        584       0.00      0.00      0.00         2\n",
      "        589       0.00      0.00      0.00         1\n",
      "        622       0.88      0.88      0.88        16\n",
      "        633       1.00      1.00      1.00         1\n",
      "        641       0.00      0.00      0.00        25\n",
      "        646       0.00      0.00      0.00         1\n",
      "        657       0.95      1.00      0.97        18\n",
      "        665       0.00      0.00      0.00         3\n",
      "        666       0.00      0.00      0.00         3\n",
      "        672       0.00      0.00      0.00         1\n",
      "        677       0.72      0.67      0.69        66\n",
      "        682       0.00      0.00      0.00         8\n",
      "        683       0.00      0.00      0.00         3\n",
      "        688       0.00      0.00      0.00         2\n",
      "        689       0.00      0.00      0.00         3\n",
      "        694       0.00      0.00      0.00         1\n",
      "        703       1.00      1.00      1.00         3\n",
      "        707       0.82      1.00      0.90        56\n",
      "        708       0.00      0.00      0.00         1\n",
      "        712       1.00      0.80      0.89         5\n",
      "        717       0.00      0.00      0.00         3\n",
      "        721       0.00      0.00      0.00         5\n",
      "        729       0.00      0.00      0.00         1\n",
      "        731       0.00      0.00      0.00         2\n",
      "        734       0.00      0.00      0.00         3\n",
      "        741       0.00      0.00      0.00         1\n",
      "        790       0.00      0.00      0.00         1\n",
      "        793       0.00      0.00      0.00         1\n",
      "        816       0.00      0.00      0.00         1\n",
      "        845       0.00      0.00      0.00         3\n",
      "        851       0.40      1.00      0.57         2\n",
      "        852       0.72      1.00      0.84        13\n",
      "        859       0.00      0.00      0.00         1\n",
      "        868       0.00      0.00      0.00         1\n",
      "        870       1.00      0.33      0.50        15\n",
      "        876       0.00      0.00      0.00         1\n",
      "        877       0.00      0.00      0.00         1\n",
      "        884       0.00      0.00      0.00         1\n",
      "        885       0.00      0.00      0.00         2\n",
      "        886       0.00      0.00      0.00         1\n",
      "        890       0.88      0.97      0.93        39\n",
      "        891       0.00      0.00      0.00         1\n",
      "        903       0.00      0.00      0.00         2\n",
      "        915       0.00      0.00      0.00         2\n",
      "        921       0.00      0.00      0.00         0\n",
      "        922       1.00      1.00      1.00         4\n",
      "        937       0.00      0.00      0.00         2\n",
      "        939       0.91      1.00      0.95       285\n",
      "        948       0.00      0.00      0.00         1\n",
      "        951       0.41      0.56      0.47        25\n",
      "        967       0.00      0.00      0.00         4\n",
      "        969       0.68      0.59      0.63        46\n",
      "        974       0.00      0.00      0.00         1\n",
      "        989       0.00      0.00      0.00         1\n",
      "        996       0.00      0.00      0.00         6\n",
      "        998       1.00      1.00      1.00         1\n",
      "       1003       0.00      0.00      0.00         5\n",
      "       1005       0.00      0.00      0.00         1\n",
      "       1019       0.00      0.00      0.00         2\n",
      "       1028       0.50      1.00      0.67         2\n",
      "\n",
      "avg / total       0.68      0.73      0.69      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
